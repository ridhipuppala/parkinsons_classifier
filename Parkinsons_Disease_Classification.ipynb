{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parkinsons_Disease_Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKh718XpWw82"
      },
      "source": [
        "# Outline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJvB7oibW0ep"
      },
      "source": [
        "This project is for predicting if a person has Parkinson's disease from voice samples. We can use 15 basic voice tremor parameters to predict if he/she is suffering from Parkinson's disease. They are Jitter, Shimmer, HNR, NHR, Frequency etc.\n",
        "\n",
        "Dataset (UCI ML Repository):\n",
        "Training\n",
        "\n",
        "\n",
        "https://drive.google.com/file/d/10rpHaDYM76itD22mjQvrksRWEM3pJbwE/view?usp=sharing\n",
        "\n",
        "Testing\n",
        "\n",
        "https://drive.google.com/file/d/1m7XSSOrH6lqX684SwYiKMyTtG7CDb-3i/view?usp=sharing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkSEN0viWL1_"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.decomposition import PCA \n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix \n",
        "from sklearn.model_selection import GridSearchCV "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQreATXkWhKW"
      },
      "source": [
        "df = pd.read_csv('parkinsons.csv') \n",
        "df.head() \n",
        "df.drop('name', axis = 1, inplace = True) \n",
        "df.head() \n",
        "df.columns \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CPAa3TDXqd8"
      },
      "source": [
        "grr   =   pd.plotting.scatter_matrix(df,   c=df['status'],   figsize   =   (15,15),   marker   =   'o',  \n",
        "hist_kwds = {'bins': 20}, s = 60, alpha = 0.5) \n",
        "len(df) \n",
        "df.describe() \n",
        "df.corr() \n",
        "pd.value_counts(df.status) \n",
        "X_train,   X_test,   y_train,   y_test   =   train_test_split(df.drop('status',   axis   =   1),  \n",
        "df['status']) \n",
        "pd.value_counts(y_train) \n",
        "X_train_norm = (X_train - X_train.mean())/X_train.std() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVOuU6TTXtk4"
      },
      "source": [
        "grr   =   pd.plotting.scatter_matrix(df,   c=df['status'],   figsize   =   (15,15),   marker   =   'o',  \n",
        "hist_kwds = {'bins': 20}, s = 60, alpha = 0.5) \n",
        "len(df) \n",
        "df.describe() \n",
        "df.corr() \n",
        "pd.value_counts(df.status) \n",
        "X_train,   X_test,   y_train,   y_test   =   train_test_split(df.drop('status',   axis   =   1),  \n",
        "df['status']) \n",
        "pd.value_counts(y_train) \n",
        "X_train_norm = (X_train - X_train.mean())/X_train.std() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm6ZSsLxXwyE"
      },
      "source": [
        "X_test_norm = (X_test - X_train.mean())/X_train.std() \n",
        "pca = PCA() \n",
        "pca.fit(X_train_norm) \n",
        "sum(np.cumsum(pca.explained_variance_ratio_) <= 0.99) \n",
        "np.cumsum(pca.explained_variance_ratio_) \n",
        "pca = PCA(7) \n",
        "pca.fit(X_train_norm) \n",
        "X_train_pca = pca.transform(X_train_norm) \n",
        "X_test_pca = pca.transform(X_test_norm) \n",
        "X_train_pca.shape \n",
        "X_test_pca.shape "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV5vxcSAXyWv"
      },
      "source": [
        "lda = LDA() \n",
        "lda.fit(X_train_norm, y_train) \n",
        "X_train_lda = lda.transform(X_train_norm) \n",
        "X_test_lda = lda.transform(X_test_norm) \n",
        "X_train_lda.shape \n",
        "X_test_lda.shape "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOoIHW53XzOz"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdsXHuq2Xy4Z"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier as RF \n",
        "from sklearn.linear_model import LogisticRegression as LR \n",
        "from sklearn.neighbors import KNeighborsClassifier as KNN \n",
        "from sklearn.metrics import classification_report, accuracy_score \n",
        "#from sklearn. import  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAACLCgmX6PR"
      },
      "source": [
        "rf = RF() \n",
        "lr = LR() \n",
        "knn = KNN() \n",
        " \n",
        "rf.fit(X_train_pca, y_train) \n",
        "pred = rf.predict(X_test_pca) \n",
        "rf.score(X_train_pca, y_train) \n",
        "rf.score(X_test_pca, y_test) \n",
        " \n",
        "print(classification_report(y_test, pred)) \n",
        "rf.fit(X_train, y_train) \n",
        "rf.score(X_train, y_train) \n",
        "rf.score(X_test, y_test) \n",
        "rf.feature_importances_ \n",
        "\n",
        "lr.fit(X_train_pca, y_train) \n",
        "pred = lr.predict(X_test_pca) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMy_pkkqX9cA"
      },
      "source": [
        "print(lr.score(X_train_pca, y_train)) \n",
        "print(lr.score(X_test_pca, y_test)) \n",
        "lr = LR(C = 0.1) \n",
        "lr.fit(X_train_norm, y_train) \n",
        "lr.score(X_train_norm, y_train) \n",
        "lr.score(X_test_norm, y_test) \n",
        "lr.coef_ \n",
        "knn.fit(X_train_pca, y_train) \n",
        "pred = knn.predict(X_test_pca) \n",
        "print(knn.score(X_train_pca, y_train)) \n",
        "print(knn.score(X_test_pca, y_test)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n5Ou3k3X_OZ"
      },
      "source": [
        "pred = lda.predict(X_test_norm) \n",
        "accuracy_score(y_test, pred) \n",
        " \n",
        "knn.fit(X_train, y_train) \n",
        "knn.score(X_test, y_test) \n",
        "neig = [1,2, 3, 4, 5, 6, 8, 10] \n",
        "train_ls = [] \n",
        "test_ls = [] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pXsWpmDYA4v"
      },
      "source": [
        "for n in neig: \n",
        "    knn = KNN(n) \n",
        "    knn.fit(X_train_pca, y_train) \n",
        "    train_ls.append(knn.score(X_train_pca, y_train)) \n",
        "    test_ls.append(knn.score(X_test_pca, y_test)) \n",
        "plt.plot(neig, train_ls, label = 'Training Score') \n",
        "plt.plot(neig, test_ls, label = 'Test Score') \n",
        "plt.legend() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUeXaoHQYHHV"
      },
      "source": [
        "Optimal number of neigbours for this problem is 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1MwkEEuYGkq"
      },
      "source": [
        "knn = KNN(5) \n",
        "knn.fit(X_train_pca, y_train) \n",
        "pred = knn.predict(X_test_pca) \n",
        "print(classification_report(1-y_test, 1-pred)) \n",
        "knn.score(X_test_pca, y_test) \n",
        "X_train.columns \n",
        "tf = pd.read_csv('test.csv') \n",
        "tf.head() \n",
        "tf.drop('name', axis = 1, inplace = True) \n",
        "X_ut = tf.drop('status', axis = 1) \n",
        "print (X_ut) \n",
        "X_ut_norm = (X_ut - X_train.mean())/X_train.std() \n",
        "print (X_ut_norm) \n",
        "X_ut_pca = pca.transform(X_ut_norm) \n",
        "predictions = knn.predict(X_ut_pca) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0anXsUlPYeoK"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLnSF37vYPzi"
      },
      "source": [
        "\n",
        "\n",
        "[1] https://en.wikipedia.org/wiki/Parkinson%27s_disease \n",
        "\n",
        "[2]   Praat   Software:   Paul   Boersma   and   David   Weenink   of   the   University   of  \n",
        "Amsterdam. \n",
        "\n",
        "[3] http://www.parkinson.org/understanding-parkinsons "
      ]
    }
  ]
}